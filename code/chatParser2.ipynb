{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce63a9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 249 blocks. Output written to sas_blocks.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Define regex patterns for SAS constructs (case-insensitive)\n",
    "PATTERNS = {\n",
    "    'PROC': re.compile(r'^\\s*proc\\s+(?P<name>\\w+)(?P<params>[^;]*);', re.IGNORECASE),\n",
    "    'DATA_STEP': re.compile(r'^\\s*data\\s+(?P<name>[^;\\(]+)', re.IGNORECASE),\n",
    "    'PROC_SQL_START': re.compile(r'^\\s*proc\\s+sql\\b', re.IGNORECASE),\n",
    "    'PROC_SQL_END': re.compile(r'^\\s*quit\\s*;', re.IGNORECASE),\n",
    "    'MACRO_DEF': re.compile(r'^\\s*%macro\\s+(?P<name>\\w+)(?:\\s*\\((?P<params>[^)]*)\\))?;', re.IGNORECASE),\n",
    "    'MACRO_END': re.compile(r'^\\s*%mend\\b', re.IGNORECASE),\n",
    "    'INCLUDE': re.compile(r'^\\s*%include\\s+[\"\\'](?P<path>[^\"\\']+)[\"\\']\\s*;', re.IGNORECASE),\n",
    "    'LIBNAME': re.compile(r'^\\s*libname\\s+(?P<name>\\w+)\\s+(?P<path>[^;]+);', re.IGNORECASE),\n",
    "    'FILENAME': re.compile(r'^\\s*filename\\s+(?P<name>\\w+)\\s+(?P<path>[^;]+);', re.IGNORECASE),\n",
    "    'OPTIONS': re.compile(r'^\\s*options\\s+(?P<opts>[^;]+);', re.IGNORECASE),\n",
    "    'LET': re.compile(r'^\\s*let\\s+(?P<assign>[^;]+);', re.IGNORECASE)\n",
    "}\n",
    "\n",
    "\n",
    "# Patterns for table references\n",
    "TABLE_PATTERNS = {\n",
    "    'PROC': {\n",
    "        'IN': re.compile(r'\\b(?:data=|from\\s*)(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "        'OUT': re.compile(r'\\b(?:out=|create\\s+table\\s*)(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "    },\n",
    "    'DATA_STEP': {\n",
    "        'IN': re.compile(r'\\b(?:set|merge)\\s+(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "        'OUT': re.compile(r'^\\s*data\\s+(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "    },\n",
    "    'SQL': {\n",
    "        'IN': re.compile(r'\\b(?:from|join)\\s+(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "        'OUT': re.compile(r'\\b(?:create\\s+table|into)\\s+(?P<table>[\\w\\.]+)', re.IGNORECASE),\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def extract_tables(code_lines, context):\n",
    "    \"\"\"\n",
    "    Extract input/output tables from a list of code lines given context ('PROC', 'DATA_STEP', 'SQL').\n",
    "    \"\"\"\n",
    "    inputs, outputs = set(), set()\n",
    "    for line in code_lines:\n",
    "        pats = TABLE_PATTERNS.get(context, {})\n",
    "        for direction, pat in pats.items():\n",
    "            for m in pat.finditer(line):\n",
    "                if direction == 'IN':\n",
    "                    inputs.add(m.group('table'))\n",
    "                else:\n",
    "                    outputs.add(m.group('table'))\n",
    "    return list(inputs), list(outputs)\n",
    "\n",
    "\n",
    "def parse_file(file_path):\n",
    "    \"\"\"\n",
    "    Parse a single .sas file, return list of block dicts.\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    i = 0\n",
    "    in_sql = False\n",
    "    in_macro = False\n",
    "    current = None\n",
    "\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        # Detect macro definitions\n",
    "        if not in_macro:\n",
    "            m = PATTERNS['MACRO_DEF'].match(line)\n",
    "            if m:\n",
    "                in_macro = True\n",
    "                current = {\n",
    "                    'block_type': 'MACRO',\n",
    "                    'block_name': m.group('name'),\n",
    "                    'params': m.group('params') or '',\n",
    "                    'raw_code': []\n",
    "                }\n",
    "        if in_macro and current:\n",
    "            current['raw_code'].append(line)\n",
    "            if PATTERNS['MACRO_END'].match(line):\n",
    "                blocks.append(current)\n",
    "                in_macro = False\n",
    "                current = None\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detect PROC SQL\n",
    "        if not in_sql and PATTERNS['PROC_SQL_START'].match(line):\n",
    "            in_sql = True\n",
    "            current = {'block_type': 'PROC SQL', 'block_name': '', 'raw_code': []}\n",
    "        if in_sql and current:\n",
    "            current['raw_code'].append(line)\n",
    "            if PATTERNS['PROC_SQL_END'].match(line):\n",
    "                # Extract tables\n",
    "                inputs, outputs = extract_tables(current['raw_code'], 'SQL')\n",
    "                current.update({'input_tables': inputs, 'output_tables': outputs})\n",
    "                blocks.append(current)\n",
    "                in_sql = False\n",
    "                current = None\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # PROC steps\n",
    "        m = PATTERNS['PROC'].match(line)\n",
    "        if m:\n",
    "            current = {\n",
    "                'block_type': f\"PROC {m.group('name').upper()}\",\n",
    "                'block_name': m.group('name'),\n",
    "                'raw_code': [line]\n",
    "            }\n",
    "            # consume until semicolon ending the step (simple assumption)\n",
    "            while i+1 < len(lines) and not lines[i].strip().endswith(';'):\n",
    "                i += 1\n",
    "                current['raw_code'].append(lines[i])\n",
    "            # extract tables\n",
    "            inputs, outputs = extract_tables(current['raw_code'], 'PROC')\n",
    "            current.update({'input_tables': inputs, 'output_tables': outputs})\n",
    "            blocks.append(current)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # DATA step\n",
    "        m = PATTERNS['DATA_STEP'].match(line)\n",
    "        if m:\n",
    "            current = {\n",
    "                'block_type': 'DATA_STEP',\n",
    "                'block_name': m.group('name').strip(),\n",
    "                'raw_code': [line]\n",
    "            }\n",
    "            # find end via run; or semicolon on submit\n",
    "            while i+1 < len(lines) and not re.match(r'^\\s*run\\s*;', lines[i+1], re.IGNORECASE):\n",
    "                i += 1\n",
    "                current['raw_code'].append(lines[i])\n",
    "            # append the run; if present\n",
    "            if i+1 < len(lines):\n",
    "                i += 1\n",
    "                current['raw_code'].append(lines[i])\n",
    "            inputs, outputs = extract_tables(current['raw_code'], 'DATA_STEP')\n",
    "            current.update({'input_tables': inputs, 'output_tables': outputs})\n",
    "            blocks.append(current)\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Other single-line constructs\n",
    "        for key in ['INCLUDE', 'LIBNAME', 'FILENAME', 'OPTIONS', 'LET']:\n",
    "            m = PATTERNS[key].match(line)\n",
    "            if m:\n",
    "                blocks.append({\n",
    "                    'block_type': key,\n",
    "                    'block_name': m.groupdict().get('name') or m.groupdict().get('path') or m.groupdict().get('opts') or m.groupdict().get('assign'),\n",
    "                    'input_tables': [],\n",
    "                    'output_tables': [],\n",
    "                    'raw_code': [line]\n",
    "                })\n",
    "                break\n",
    "        i += 1\n",
    "\n",
    "    # Add file name to each\n",
    "    for b in blocks:\n",
    "        b['file_name'] = os.path.basename(file_path)\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def parse_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Walk through folder, parse all .sas files, return DataFrame.\n",
    "    \"\"\"\n",
    "    all_blocks = []\n",
    "    for sas_file in glob.glob(os.path.join(folder_path, '*.sas')):\n",
    "        all_blocks.extend(parse_file(sas_file))\n",
    "    df = pd.DataFrame(all_blocks, columns=['file_name', 'block_type', 'block_name', 'input_tables', 'output_tables', 'raw_code'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    sas_folder= \"../data\"\n",
    "    df = parse_folder(sas_folder)\n",
    "    # Convert raw_code lists to single strings\n",
    "    df['raw_code'] = df['raw_code'].apply(lambda lines: ''.join(lines))\n",
    "    output='sas_blocks.xlsx'\n",
    "    df.to_excel(output, index=False)\n",
    "    print(f\"Parsed {len(df)} blocks. Output written to {output}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f06702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 249 blocks. Output written to sas_blocks.xlsx\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
